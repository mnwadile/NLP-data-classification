{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing ML, Data Preprocessig and NLP Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library that contains punctuation\n",
    "import string\n",
    "string.punctuation\n",
    "\n",
    "#defining function for tokenization\n",
    "import re\n",
    "\n",
    "#importing nlp library\n",
    "import nltk\n",
    "#Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')    ## Download it one time\n",
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#!pip install wordninja\n",
    "import wordninja\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for model-building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#for word embedding\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To model the Gaussian Navie Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_list = ['Components', 'Delivery and Customer Support',\n",
    "       'Design and Aesthetics', 'Dimensions', 'Features', 'Functionality',\n",
    "       'Installation', 'Material', 'Price', 'Quality', 'Usability',\n",
    "       'Polarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Data Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "def tokenization(text):\n",
    "    #tokens = re.split('W+',text)\n",
    "    #re.split('\\W+', test_string)\n",
    "    return re.split('\\W+', text)\n",
    "\n",
    "def tokenization_advance(text):\n",
    "    unique_list = []\n",
    "    #temp_list = [unique_list.extend(wordninja.split(i)) if len(i) >= 13 else unique_list.extend(i) for i in text]\n",
    "    for i in text:\n",
    "        if(len(i) >= 15):\n",
    "            unique_list.extend(wordninja.split(i))\n",
    "        else:\n",
    "            unique_list.append(i)\n",
    "    #temp_list = [unique_list.extend(wordninja.split(i)) for i in text]\n",
    "    return unique_list\n",
    "\n",
    "#defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "\n",
    "def make_sentence(text):\n",
    "    str_output = ''\n",
    "    for i in text:\n",
    "        str_output = str_output + i + ' ' \n",
    "    str_output = str_output.strip()\n",
    "    return str_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Training and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the puntuation free text\n",
    "train_df['clean_msg']= train_df['Review'].apply(lambda x:remove_punctuation(x))\n",
    "#train_df.head()\n",
    "train_df['msg_lower']= train_df['clean_msg'].apply(lambda x: x.lower())\n",
    "#applying function to the column\n",
    "train_df['msg_tokenied']= train_df['msg_lower'].apply(lambda x: tokenization(x))\n",
    "#train_df['msg_tokenied']= [tokenization(i) for i in train_df['msg_lower']]\n",
    "train_df['msg_tokenied_separate']= train_df['msg_tokenied'].apply(lambda x: tokenization_advance(x))\n",
    "#applying the function\n",
    "train_df['no_stopwords']= train_df['msg_tokenied_separate'].apply(lambda x:remove_stopwords(x))\n",
    "train_df['msg_lemmatized']=train_df['no_stopwords'].apply(lambda x:lemmatizer(x))\n",
    "train_df['sentence']=train_df['msg_lemmatized'].apply(lambda x:make_sentence(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the puntuation free text\n",
    "test_df['clean_msg']= test_df['Review'].apply(lambda x:remove_punctuation(x))\n",
    "#test_df.head()\n",
    "test_df['msg_lower']= test_df['clean_msg'].apply(lambda x: x.lower())\n",
    "#applying function to the column\n",
    "test_df['msg_tokenied']= test_df['msg_lower'].apply(lambda x: tokenization(x))\n",
    "#test_df['msg_tokenied']= [tokenization(i) for i in test_df['msg_lower']]\n",
    "test_df['msg_tokenied_separate']= test_df['msg_tokenied'].apply(lambda x: tokenization_advance(x))\n",
    "#applying the function\n",
    "test_df['no_stopwords']= test_df['msg_tokenied_separate'].apply(lambda x:remove_stopwords(x))\n",
    "test_df['msg_lemmatized']=test_df['no_stopwords'].apply(lambda x:lemmatizer(x))\n",
    "test_df['sentence']=test_df['msg_lemmatized'].apply(lambda x:make_sentence(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9660069848661234\n",
      "[[3951  146]\n",
      " [   0  198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      4097\n",
      "           1       0.58      1.00      0.73       198\n",
      "\n",
      "    accuracy                           0.97      4295\n",
      "   macro avg       0.79      0.98      0.86      4295\n",
      "weighted avg       0.98      0.97      0.97      4295\n",
      "\n",
      "0.9163498098859315\n",
      "[[1644  121]\n",
      " [  33   43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1765\n",
      "           1       0.26      0.57      0.36        76\n",
      "\n",
      "    accuracy                           0.92      1841\n",
      "   macro avg       0.62      0.75      0.66      1841\n",
      "weighted avg       0.95      0.92      0.93      1841\n",
      "\n",
      "0.9860302677532014\n",
      "[[4114   60]\n",
      " [   0  121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4174\n",
      "           1       0.67      1.00      0.80       121\n",
      "\n",
      "    accuracy                           0.99      4295\n",
      "   macro avg       0.83      0.99      0.90      4295\n",
      "weighted avg       0.99      0.99      0.99      4295\n",
      "\n",
      "0.957631721890277\n",
      "[[1724   59]\n",
      " [  19   39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1783\n",
      "           1       0.40      0.67      0.50        58\n",
      "\n",
      "    accuracy                           0.96      1841\n",
      "   macro avg       0.69      0.82      0.74      1841\n",
      "weighted avg       0.97      0.96      0.96      1841\n",
      "\n",
      "0.9809080325960419\n",
      "[[3766   80]\n",
      " [   2  447]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3846\n",
      "           1       0.85      1.00      0.92       449\n",
      "\n",
      "    accuracy                           0.98      4295\n",
      "   macro avg       0.92      0.99      0.95      4295\n",
      "weighted avg       0.98      0.98      0.98      4295\n",
      "\n",
      "0.9038565996740902\n",
      "[[1530  110]\n",
      " [  67  134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1640\n",
      "           1       0.55      0.67      0.60       201\n",
      "\n",
      "    accuracy                           0.90      1841\n",
      "   macro avg       0.75      0.80      0.77      1841\n",
      "weighted avg       0.91      0.90      0.91      1841\n",
      "\n",
      "0.9837019790454016\n",
      "[[3724   69]\n",
      " [   1  501]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3793\n",
      "           1       0.88      1.00      0.93       502\n",
      "\n",
      "    accuracy                           0.98      4295\n",
      "   macro avg       0.94      0.99      0.96      4295\n",
      "weighted avg       0.99      0.98      0.98      4295\n",
      "\n",
      "0.9212384573601303\n",
      "[[1569   79]\n",
      " [  66  127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1648\n",
      "           1       0.62      0.66      0.64       193\n",
      "\n",
      "    accuracy                           0.92      1841\n",
      "   macro avg       0.79      0.81      0.80      1841\n",
      "weighted avg       0.92      0.92      0.92      1841\n",
      "\n",
      "0.9681024447031432\n",
      "[[3929  137]\n",
      " [   0  229]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      4066\n",
      "           1       0.63      1.00      0.77       229\n",
      "\n",
      "    accuracy                           0.97      4295\n",
      "   macro avg       0.81      0.98      0.88      4295\n",
      "weighted avg       0.98      0.97      0.97      4295\n",
      "\n",
      "0.9114611624117328\n",
      "[[1629  128]\n",
      " [  35   49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1757\n",
      "           1       0.28      0.58      0.38        84\n",
      "\n",
      "    accuracy                           0.91      1841\n",
      "   macro avg       0.63      0.76      0.66      1841\n",
      "weighted avg       0.95      0.91      0.93      1841\n",
      "\n",
      "0.9576251455180442\n",
      "[[2415  119]\n",
      " [  63 1698]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      2534\n",
      "           1       0.93      0.96      0.95      1761\n",
      "\n",
      "    accuracy                           0.96      4295\n",
      "   macro avg       0.95      0.96      0.96      4295\n",
      "weighted avg       0.96      0.96      0.96      4295\n",
      "\n",
      "0.8386746333514394\n",
      "[[907 157]\n",
      " [140 637]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      1064\n",
      "           1       0.80      0.82      0.81       777\n",
      "\n",
      "    accuracy                           0.84      1841\n",
      "   macro avg       0.83      0.84      0.84      1841\n",
      "weighted avg       0.84      0.84      0.84      1841\n",
      "\n",
      "0.9911525029103608\n",
      "[[3732   38]\n",
      " [   0  525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3770\n",
      "           1       0.93      1.00      0.97       525\n",
      "\n",
      "    accuracy                           0.99      4295\n",
      "   macro avg       0.97      0.99      0.98      4295\n",
      "weighted avg       0.99      0.99      0.99      4295\n",
      "\n",
      "0.9391634980988594\n",
      "[[1537   67]\n",
      " [  45  192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1604\n",
      "           1       0.74      0.81      0.77       237\n",
      "\n",
      "    accuracy                           0.94      1841\n",
      "   macro avg       0.86      0.88      0.87      1841\n",
      "weighted avg       0.94      0.94      0.94      1841\n",
      "\n",
      "0.9692665890570431\n",
      "[[4042  132]\n",
      " [   0  121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      4174\n",
      "           1       0.48      1.00      0.65       121\n",
      "\n",
      "    accuracy                           0.97      4295\n",
      "   macro avg       0.74      0.98      0.82      4295\n",
      "weighted avg       0.99      0.97      0.97      4295\n",
      "\n",
      "0.9402498642042368\n",
      "[[1705  102]\n",
      " [   8   26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1807\n",
      "           1       0.20      0.76      0.32        34\n",
      "\n",
      "    accuracy                           0.94      1841\n",
      "   macro avg       0.60      0.85      0.64      1841\n",
      "weighted avg       0.98      0.94      0.96      1841\n",
      "\n",
      "0.9890570430733411\n",
      "[[3647   44]\n",
      " [   3  601]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3691\n",
      "           1       0.93      1.00      0.96       604\n",
      "\n",
      "    accuracy                           0.99      4295\n",
      "   macro avg       0.97      0.99      0.98      4295\n",
      "weighted avg       0.99      0.99      0.99      4295\n",
      "\n",
      "0.9467680608365019\n",
      "[[1541   50]\n",
      " [  48  202]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1591\n",
      "           1       0.80      0.81      0.80       250\n",
      "\n",
      "    accuracy                           0.95      1841\n",
      "   macro avg       0.89      0.89      0.89      1841\n",
      "weighted avg       0.95      0.95      0.95      1841\n",
      "\n",
      "0.9613504074505239\n",
      "[[2654  111]\n",
      " [  55 1475]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      2765\n",
      "           1       0.93      0.96      0.95      1530\n",
      "\n",
      "    accuracy                           0.96      4295\n",
      "   macro avg       0.95      0.96      0.96      4295\n",
      "weighted avg       0.96      0.96      0.96      4295\n",
      "\n",
      "0.8451928299837045\n",
      "[[1035  159]\n",
      " [ 126  521]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      1194\n",
      "           1       0.77      0.81      0.79       647\n",
      "\n",
      "    accuracy                           0.85      1841\n",
      "   macro avg       0.83      0.84      0.83      1841\n",
      "weighted avg       0.85      0.85      0.85      1841\n",
      "\n",
      "0.9778812572759022\n",
      "[[3356   84]\n",
      " [  11  844]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3440\n",
      "           1       0.91      0.99      0.95       855\n",
      "\n",
      "    accuracy                           0.98      4295\n",
      "   macro avg       0.95      0.98      0.97      4295\n",
      "weighted avg       0.98      0.98      0.98      4295\n",
      "\n",
      "0.8940793047256925\n",
      "[[1359  108]\n",
      " [  87  287]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      1467\n",
      "           1       0.73      0.77      0.75       374\n",
      "\n",
      "    accuracy                           0.89      1841\n",
      "   macro avg       0.83      0.85      0.84      1841\n",
      "weighted avg       0.90      0.89      0.90      1841\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9685681024447031\n",
      "[[ 955    4]\n",
      " [ 131 3205]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       959\n",
      "           1       1.00      0.96      0.98      3336\n",
      "\n",
      "    accuracy                           0.97      4295\n",
      "   macro avg       0.94      0.98      0.96      4295\n",
      "weighted avg       0.97      0.97      0.97      4295\n",
      "\n",
      "0.8756110809342749\n",
      "[[ 331   76]\n",
      " [ 153 1281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74       407\n",
      "           1       0.94      0.89      0.92      1434\n",
      "\n",
      "    accuracy                           0.88      1841\n",
      "   macro avg       0.81      0.85      0.83      1841\n",
      "weighted avg       0.89      0.88      0.88      1841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in target_column_list:\n",
    "    vectorizer = TfidfVectorizer(max_features=2000, sublinear_tf= False, norm ='l1', ngram_range = (1,2))\n",
    "    processed_features = vectorizer.fit_transform(train_df['sentence']).toarray()\n",
    "    #processed_features_test = vectorizer.fit_transform(test_df['sentence']).toarray()\n",
    "    labels = train_df[i]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.3, random_state=0)\n",
    "\n",
    "    LR_model = LogisticRegression(solver='saga', penalty='none', class_weight= 'balanced', random_state=0)\n",
    "    LR_model.fit(X_train, y_train)\n",
    "    y_train_predict = LR_model.predict(X_train)\n",
    "    model_score = LR_model.score(X_train, y_train)                      ## Accuracy\n",
    "    print(model_score)\n",
    "    print(metrics.confusion_matrix(y_train, y_train_predict))          ## confusion_matrix\n",
    "    print(metrics.classification_report(y_train, y_train_predict))     ## classification_report\n",
    "\n",
    "    y_test_predict = LR_model.predict(X_test)\n",
    "    model_score = LR_model.score(X_test, y_test)                      ## Accuracy\n",
    "    print(model_score)\n",
    "    print(metrics.confusion_matrix(y_test, y_test_predict))          ## confusion_matrix\n",
    "    print(metrics.classification_report(y_test, y_test_predict))     ## classification_report\n",
    "\n",
    "    LR_model = LogisticRegression(solver='saga', penalty='none', class_weight= 'balanced', random_state=0)\n",
    "    LR_model.fit(processed_features, labels)\n",
    "\n",
    "    processed_features_test = vectorizer.transform(test_df['sentence']).toarray()\n",
    "    labels = test_df[i]\n",
    "\n",
    "    y_test_predict = LR_model.predict(processed_features_test)\n",
    "\n",
    "    probs = LR_model.predict_proba(processed_features_test)\n",
    "    probs = probs[:, 1]\n",
    "    final_df[i] = probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Components</th>\n",
       "      <th>Delivery and Customer Support</th>\n",
       "      <th>Design and Aesthetics</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Features</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Material</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.983101</td>\n",
       "      <td>0.067344</td>\n",
       "      <td>0.052661</td>\n",
       "      <td>0.080811</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>7.415637e-01</td>\n",
       "      <td>0.022744</td>\n",
       "      <td>0.742178</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.309293</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>2.458514e-05</td>\n",
       "      <td>0.020265</td>\n",
       "      <td>0.069112</td>\n",
       "      <td>0.150672</td>\n",
       "      <td>0.997559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.041046</td>\n",
       "      <td>0.008762</td>\n",
       "      <td>3.634202e-12</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970305</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>0.151059</td>\n",
       "      <td>0.146210</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.015313</td>\n",
       "      <td>2.830082e-05</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.365146</td>\n",
       "      <td>0.232309</td>\n",
       "      <td>0.962767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.168185</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.022483</td>\n",
       "      <td>0.318097</td>\n",
       "      <td>0.995071</td>\n",
       "      <td>0.041705</td>\n",
       "      <td>7.334437e-07</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Components  Delivery and Customer Support  Design and Aesthetics  \\\n",
       "0    0.983101                       0.067344               0.052661   \n",
       "1    0.000947                       0.309293               0.003103   \n",
       "2    0.000040                       0.000240               0.000293   \n",
       "3    0.970305                       0.048227               0.151059   \n",
       "4    0.000002                       0.168185               0.001752   \n",
       "\n",
       "   Dimensions  Features  Functionality  Installation      Material     Price  \\\n",
       "0    0.080811  0.003175       0.003264      0.018721  7.415637e-01  0.022744   \n",
       "1    0.003719  0.000390       0.999141      0.000208  2.458514e-05  0.020265   \n",
       "2    0.000217  0.000051       0.041046      0.008762  3.634202e-12  0.010810   \n",
       "3    0.146210  0.000449       0.999884      0.015313  2.830082e-05  0.022688   \n",
       "4    0.022483  0.318097       0.995071      0.041705  7.334437e-07  0.000172   \n",
       "\n",
       "    Quality  Usability  Polarity  \n",
       "0  0.742178   0.006829  0.002306  \n",
       "1  0.069112   0.150672  0.997559  \n",
       "2  0.009340   1.000000  0.999996  \n",
       "3  0.365146   0.232309  0.962767  \n",
       "4  0.998302   0.002306  1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final_df_v10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
